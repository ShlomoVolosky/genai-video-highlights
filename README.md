# ğŸ¬ GenAI Video Highlights System

A comprehensive AI-powered video processing and chat system that extracts meaningful highlights from videos and enables natural language interaction with the processed content.

## ğŸ—ï¸ System Overview

This project consists of three main components:

### ğŸ“¹ **Step 1: Video Processing Pipeline**
Automated video analysis and highlight extraction system that processes videos to identify and extract meaningful moments.

**Key Features:**
- **Multi-format Video Support**: Downloads and processes various video formats
- **Scene Detection**: Identifies scene transitions and visual changes
- **Object Detection**: Recognizes objects, people, and activities in video frames
- **Audio Transcription**: Converts speech to text using Whisper
- **LLM Analysis**: Uses Claude/Gemini/OpenAI to analyze and summarize highlights
- **Vector Embeddings**: Stores semantic embeddings for intelligent search
- **Database Storage**: PostgreSQL with pgvector for efficient storage and retrieval

**Technologies:** Python, OpenCV, FFmpeg, Whisper, PostgreSQL, pgvector, Docker

---

### ğŸ’¬ **Step 2: Interactive Chat Interface**
Natural language chat system that allows users to ask questions about processed video highlights.

**Key Features:**
- **Natural Language Processing**: Understands complex questions like "What happened during the journey?"
- **Dual Search System**: 
  - Primary: Semantic vector search using LLM embeddings
  - Fallback: Smart keyword extraction with stop-word filtering
- **React Frontend**: Clean, responsive chat interface
- **FastAPI Backend**: RESTful API with automatic documentation
- **Database-Only Responses**: Returns content directly from processed highlights
- **Intelligent Fallback**: Automatically switches search methods for optimal results

**Technologies:** React, FastAPI, SQLAlchemy, pgvector, Docker

**Example Queries:**
- "What happened during the journey?" â†’ Returns travel/exploration scenes
- "Show me dramatic moments" â†’ Finds fire, action, high-intensity scenes
- "Find scenes with movement" â†’ Locates travel, motion, dynamic content

---

### ğŸ§  **Bonus: Neural Network Tic-Tac-Toe Player**
Self-learning AI that masters Tic-Tac-Toe using reinforcement learning with TensorFlow.

**Key Features:**
- **REINFORCE Algorithm**: Policy gradient learning from scratch
- **Three Difficulty Levels**:
  - Easy: vs Random opponent
  - Medium: vs Heuristic opponent  
  - Hard: Self-play training
- **TensorFlow Implementation**: CPU-only neural network
- **Interactive GUI**: Tkinter interface for human vs AI gameplay
- **Training Visualization**: Loss curves and win/draw/loss rate plots
- **Model Persistence**: Saves trained models for later use

**Technologies:** TensorFlow 2, Keras, NumPy, Matplotlib, Tkinter

---

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Python 3.10+
- LLM API key (Claude/Gemini/OpenAI) - optional for Step 2

### Step 1: Video Processing
```bash
# Start database and process videos
docker-compose up --build
```

### Step 2: Interactive Chat
```bash
# Start chat system (includes database, API, and frontend)
docker-compose -f docker-compose.chat.yml up --build

# Access chat interface
open http://localhost:5173
```

### Bonus: Tic-Tac-Toe AI
```bash
# Setup virtual environment
python3 -m venv .venv-ttt && source .venv-ttt/bin/activate
pip install -r requirements-bonus-ttt.txt

# Train AI (choose difficulty: easy/medium/hard)
python bonus/ttt/train.py --opponent medium --episodes 6000

# Play against AI
python bonus/ttt/game.py
```

## ğŸ“ Project Structure

```
video-highlights/
â”œâ”€â”€ app/                     # Step 1: Video processing pipeline
â”‚   â”œâ”€â”€ main.py             # Main processing script
â”‚   â”œâ”€â”€ processors/         # Video, audio, scene, object processors
â”‚   â”œâ”€â”€ llm/               # LLM clients (Claude, Gemini, OpenAI)
â”‚   â””â”€â”€ db/                # Database models and repository
â”œâ”€â”€ api/                    # Step 2: FastAPI backend
â”‚   â”œâ”€â”€ main.py            # FastAPI application
â”‚   â”œâ”€â”€ service.py         # Chat service with dual search
â”‚   â”œâ”€â”€ schemas.py         # Pydantic models
â”‚   â””â”€â”€ routers/           # API endpoints
â”œâ”€â”€ web/                    # Step 2: React frontend
â”‚   â”œâ”€â”€ src/               # React components and API client
â”‚   â”œâ”€â”€ package.json       # Dependencies
â”‚   â””â”€â”€ Dockerfile         # Frontend container
â”œâ”€â”€ bonus/                  # Bonus: Tic-Tac-Toe AI
â”‚   â””â”€â”€ ttt/               # TensorFlow reinforcement learning
â”œâ”€â”€ tests/                  # Comprehensive test suite
â”œâ”€â”€ docker-compose.yml      # Step 1 services
â”œâ”€â”€ docker-compose.chat.yml # Step 2 services
â””â”€â”€ README_*.md            # Detailed documentation
```

## ğŸ”§ Environment Configuration

Create a `.env` file:
```bash
# Database
POSTGRES_USER=appuser
POSTGRES_PASSWORD=apppass
POSTGRES_DB=highlights_db
POSTGRES_HOST=localhost
POSTGRES_PORT=5433

# LLM API Keys (choose one or more)
CLAUDE_API_KEY=your_claude_key_here
GOOGLE_API_KEY=your_gemini_key_here
OPENAI_API_KEY=your_openai_key_here

# Models
EMBEDDING_MODEL=text-embedding-004
GENERATION_MODEL=gemini-1.5-flash
```

## ğŸ“š Documentation

- **[README_STEP1.md](README_STEP1.md)** - Detailed Step 1 video processing documentation
- **[README_STEP2.md](README_STEP2.md)** - Detailed Step 2 chat system documentation  
- **[README_BONUS.md](README_BONUS.md)** - Detailed Bonus tic-tac-toe AI documentation

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test categories
pytest tests/test_step2_chat.py          # Step 2 chat functionality
pytest tests/test_repository_integration.py  # Database integration
pytest tests/test_llm_and_selector.py   # LLM integration
```

## ğŸ¯ Key Technologies

| Component | Technologies |
|-----------|-------------|
| **Video Processing** | Python, OpenCV, FFmpeg, Whisper, ultralytics |
| **Database** | PostgreSQL, pgvector, SQLAlchemy |
| **LLM Integration** | Claude, Gemini, OpenAI APIs |
| **Backend API** | FastAPI, Pydantic, uvicorn |
| **Frontend** | React, Vite, JavaScript |
| **AI/ML** | TensorFlow 2, Keras, NumPy |
| **Containerization** | Docker, Docker Compose |
| **Testing** | pytest, pytest-mock |

## âœ¨ Features Highlights

- ğŸ¬ **Multi-modal Analysis**: Combines video, audio, and visual processing
- ğŸ§  **Semantic Search**: Vector embeddings for intelligent content discovery
- ğŸ’¬ **Natural Language**: Chat with your videos using everyday language
- ğŸ”„ **Intelligent Fallback**: Robust search with automatic method switching
- ğŸ³ **Containerized**: Full Docker support for easy deployment
- ğŸ§ª **Well-Tested**: Comprehensive test suite with mocking
- ğŸ® **Bonus AI**: Self-learning game AI with visualization
- ğŸ“Š **Scalable**: Modular architecture for easy extension

## ğŸ† Project Goals Achieved

âœ… **Step 1**: Complete video processing pipeline with LLM analysis  
âœ… **Step 2**: Interactive chat system with natural language understanding  
âœ… **Bonus**: Self-learning AI with reinforcement learning  
âœ… **Integration**: Seamless data flow between all components  
âœ… **Documentation**: Comprehensive guides and examples  
âœ… **Testing**: Robust test coverage with CI/CD ready structure  

---

**Ready to explore your videos through AI-powered conversation? Start with Step 1 to process your content, then dive into Step 2 for interactive exploration!**